{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL1QtMo0UNCa",
        "outputId": "f90a9463-6018-4c38-bf5e-79070d23618c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbMquHdXg6Fm",
        "outputId": "2202a61f-87b1-46a6-9c9b-45c534541785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n",
            "Collecting playwright\n",
            "  Downloading playwright-1.49.1-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: greenlet==3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright) (3.1.1)\n",
            "Collecting pyee==12.0.0 (from playwright)\n",
            "  Downloading pyee-12.0.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee==12.0.0->playwright) (4.12.2)\n",
            "Downloading playwright-1.49.1-py3-none-manylinux1_x86_64.whl (44.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyee-12.0.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pyee, playwright\n",
            "Successfully installed playwright-1.49.1 pyee-12.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install requests\n",
        "!pip install bs4\n",
        "!pip install playwright\n",
        "#!pip install --upgrade gspread #oauth2client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!playwright install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO1ZUryZz-YP",
        "outputId": "b7fa00f2-ad9a-4e49-a2b1-cc5dac1b5628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Chromium 131.0.6778.33 (playwright build v1148)\u001b[2m from https://playwright.azureedge.net/builds/chromium/1148/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G161.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G161.3 MiB [] 0% 22.0s\u001b[0K\u001b[1G161.3 MiB [] 0% 15.5s\u001b[0K\u001b[1G161.3 MiB [] 0% 12.4s\u001b[0K\u001b[1G161.3 MiB [] 1% 6.9s\u001b[0K\u001b[1G161.3 MiB [] 1% 5.5s\u001b[0K\u001b[1G161.3 MiB [] 2% 4.8s\u001b[0K\u001b[1G161.3 MiB [] 2% 4.4s\u001b[0K\u001b[1G161.3 MiB [] 3% 4.2s\u001b[0K\u001b[1G161.3 MiB [] 3% 3.9s\u001b[0K\u001b[1G161.3 MiB [] 4% 3.7s\u001b[0K\u001b[1G161.3 MiB [] 4% 3.6s\u001b[0K\u001b[1G161.3 MiB [] 5% 3.5s\u001b[0K\u001b[1G161.3 MiB [] 5% 3.6s\u001b[0K\u001b[1G161.3 MiB [] 6% 3.5s\u001b[0K\u001b[1G161.3 MiB [] 7% 3.8s\u001b[0K\u001b[1G161.3 MiB [] 7% 4.1s\u001b[0K\u001b[1G161.3 MiB [] 7% 4.2s\u001b[0K\u001b[1G161.3 MiB [] 8% 4.3s\u001b[0K\u001b[1G161.3 MiB [] 8% 4.4s\u001b[0K\u001b[1G161.3 MiB [] 8% 4.6s\u001b[0K\u001b[1G161.3 MiB [] 8% 4.5s\u001b[0K\u001b[1G161.3 MiB [] 9% 4.3s\u001b[0K\u001b[1G161.3 MiB [] 9% 4.4s\u001b[0K\u001b[1G161.3 MiB [] 10% 4.3s\u001b[0K\u001b[1G161.3 MiB [] 10% 4.4s\u001b[0K\u001b[1G161.3 MiB [] 11% 4.3s\u001b[0K\u001b[1G161.3 MiB [] 11% 4.2s\u001b[0K\u001b[1G161.3 MiB [] 12% 4.2s\u001b[0K\u001b[1G161.3 MiB [] 13% 4.0s\u001b[0K\u001b[1G161.3 MiB [] 14% 3.8s\u001b[0K\u001b[1G161.3 MiB [] 14% 3.9s\u001b[0K\u001b[1G161.3 MiB [] 15% 3.8s\u001b[0K\u001b[1G161.3 MiB [] 16% 3.7s\u001b[0K\u001b[1G161.3 MiB [] 17% 3.6s\u001b[0K\u001b[1G161.3 MiB [] 18% 3.5s\u001b[0K\u001b[1G161.3 MiB [] 18% 3.4s\u001b[0K\u001b[1G161.3 MiB [] 19% 3.3s\u001b[0K\u001b[1G161.3 MiB [] 20% 3.2s\u001b[0K\u001b[1G161.3 MiB [] 20% 3.1s\u001b[0K\u001b[1G161.3 MiB [] 21% 3.0s\u001b[0K\u001b[1G161.3 MiB [] 22% 3.0s\u001b[0K\u001b[1G161.3 MiB [] 23% 2.9s\u001b[0K\u001b[1G161.3 MiB [] 24% 2.9s\u001b[0K\u001b[1G161.3 MiB [] 25% 2.8s\u001b[0K\u001b[1G161.3 MiB [] 25% 2.7s\u001b[0K\u001b[1G161.3 MiB [] 26% 2.8s\u001b[0K\u001b[1G161.3 MiB [] 26% 2.7s\u001b[0K\u001b[1G161.3 MiB [] 27% 2.6s\u001b[0K\u001b[1G161.3 MiB [] 28% 2.6s\u001b[0K\u001b[1G161.3 MiB [] 29% 2.6s\u001b[0K\u001b[1G161.3 MiB [] 30% 2.6s\u001b[0K\u001b[1G161.3 MiB [] 30% 2.5s\u001b[0K\u001b[1G161.3 MiB [] 31% 2.5s\u001b[0K\u001b[1G161.3 MiB [] 32% 2.4s\u001b[0K\u001b[1G161.3 MiB [] 33% 2.4s\u001b[0K\u001b[1G161.3 MiB [] 34% 2.3s\u001b[0K\u001b[1G161.3 MiB [] 35% 2.3s\u001b[0K\u001b[1G161.3 MiB [] 35% 2.2s\u001b[0K\u001b[1G161.3 MiB [] 36% 2.2s\u001b[0K\u001b[1G161.3 MiB [] 37% 2.2s\u001b[0K\u001b[1G161.3 MiB [] 38% 2.1s\u001b[0K\u001b[1G161.3 MiB [] 39% 2.0s\u001b[0K\u001b[1G161.3 MiB [] 40% 2.0s\u001b[0K\u001b[1G161.3 MiB [] 41% 1.9s\u001b[0K\u001b[1G161.3 MiB [] 42% 1.9s\u001b[0K\u001b[1G161.3 MiB [] 43% 1.9s\u001b[0K\u001b[1G161.3 MiB [] 44% 1.9s\u001b[0K\u001b[1G161.3 MiB [] 45% 1.8s\u001b[0K\u001b[1G161.3 MiB [] 46% 1.8s\u001b[0K\u001b[1G161.3 MiB [] 47% 1.7s\u001b[0K\u001b[1G161.3 MiB [] 48% 1.7s\u001b[0K\u001b[1G161.3 MiB [] 49% 1.6s\u001b[0K\u001b[1G161.3 MiB [] 50% 1.6s\u001b[0K\u001b[1G161.3 MiB [] 51% 1.5s\u001b[0K\u001b[1G161.3 MiB [] 52% 1.5s\u001b[0K\u001b[1G161.3 MiB [] 53% 1.5s\u001b[0K\u001b[1G161.3 MiB [] 54% 1.4s\u001b[0K\u001b[1G161.3 MiB [] 55% 1.4s\u001b[0K\u001b[1G161.3 MiB [] 56% 1.3s\u001b[0K\u001b[1G161.3 MiB [] 57% 1.3s\u001b[0K\u001b[1G161.3 MiB [] 58% 1.3s\u001b[0K\u001b[1G161.3 MiB [] 59% 1.2s\u001b[0K\u001b[1G161.3 MiB [] 60% 1.2s\u001b[0K\u001b[1G161.3 MiB [] 61% 1.2s\u001b[0K\u001b[1G161.3 MiB [] 62% 1.2s\u001b[0K\u001b[1G161.3 MiB [] 63% 1.2s\u001b[0K\u001b[1G161.3 MiB [] 64% 1.1s\u001b[0K\u001b[1G161.3 MiB [] 65% 1.1s\u001b[0K\u001b[1G161.3 MiB [] 66% 1.1s\u001b[0K\u001b[1G161.3 MiB [] 67% 1.1s\u001b[0K\u001b[1G161.3 MiB [] 68% 1.0s\u001b[0K\u001b[1G161.3 MiB [] 69% 1.0s\u001b[0K\u001b[1G161.3 MiB [] 71% 0.9s\u001b[0K\u001b[1G161.3 MiB [] 72% 0.9s\u001b[0K\u001b[1G161.3 MiB [] 73% 0.9s\u001b[0K\u001b[1G161.3 MiB [] 74% 0.8s\u001b[0K\u001b[1G161.3 MiB [] 75% 0.8s\u001b[0K\u001b[1G161.3 MiB [] 76% 0.7s\u001b[0K\u001b[1G161.3 MiB [] 77% 0.7s\u001b[0K\u001b[1G161.3 MiB [] 78% 0.7s\u001b[0K\u001b[1G161.3 MiB [] 79% 0.7s\u001b[0K\u001b[1G161.3 MiB [] 80% 0.6s\u001b[0K\u001b[1G161.3 MiB [] 82% 0.6s\u001b[0K\u001b[1G161.3 MiB [] 83% 0.5s\u001b[0K\u001b[1G161.3 MiB [] 84% 0.5s\u001b[0K\u001b[1G161.3 MiB [] 85% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 87% 0.4s\u001b[0K\u001b[1G161.3 MiB [] 88% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 89% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 90% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 91% 0.3s\u001b[0K\u001b[1G161.3 MiB [] 92% 0.2s\u001b[0K\u001b[1G161.3 MiB [] 93% 0.2s\u001b[0K\u001b[1G161.3 MiB [] 95% 0.1s\u001b[0K\u001b[1G161.3 MiB [] 96% 0.1s\u001b[0K\u001b[1G161.3 MiB [] 98% 0.0s\u001b[0K\u001b[1G161.3 MiB [] 99% 0.0s\u001b[0K\u001b[1G161.3 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 131.0.6778.33 (playwright build v1148) downloaded to /root/.cache/ms-playwright/chromium-1148\n",
            "Downloading Chromium Headless Shell 131.0.6778.33 (playwright build v1148)\u001b[2m from https://playwright.azureedge.net/builds/chromium/1148/chromium-headless-shell-linux.zip\u001b[22m\n",
            "\u001b[1G100.9 MiB [] 0% 0.0s\u001b[0K\u001b[1G100.9 MiB [] 0% 17.3s\u001b[0K\u001b[1G100.9 MiB [] 0% 13.8s\u001b[0K\u001b[1G100.9 MiB [] 0% 15.3s\u001b[0K\u001b[1G100.9 MiB [] 0% 9.8s\u001b[0K\u001b[1G100.9 MiB [] 1% 6.3s\u001b[0K\u001b[1G100.9 MiB [] 1% 5.4s\u001b[0K\u001b[1G100.9 MiB [] 2% 4.4s\u001b[0K\u001b[1G100.9 MiB [] 3% 3.8s\u001b[0K\u001b[1G100.9 MiB [] 4% 3.6s\u001b[0K\u001b[1G100.9 MiB [] 4% 3.4s\u001b[0K\u001b[1G100.9 MiB [] 5% 3.1s\u001b[0K\u001b[1G100.9 MiB [] 6% 3.1s\u001b[0K\u001b[1G100.9 MiB [] 6% 3.0s\u001b[0K\u001b[1G100.9 MiB [] 7% 2.9s\u001b[0K\u001b[1G100.9 MiB [] 8% 2.9s\u001b[0K\u001b[1G100.9 MiB [] 9% 2.7s\u001b[0K\u001b[1G100.9 MiB [] 10% 2.6s\u001b[0K\u001b[1G100.9 MiB [] 11% 2.7s\u001b[0K\u001b[1G100.9 MiB [] 12% 2.6s\u001b[0K\u001b[1G100.9 MiB [] 13% 2.5s\u001b[0K\u001b[1G100.9 MiB [] 14% 2.4s\u001b[0K\u001b[1G100.9 MiB [] 15% 2.3s\u001b[0K\u001b[1G100.9 MiB [] 15% 2.4s\u001b[0K\u001b[1G100.9 MiB [] 16% 2.4s\u001b[0K\u001b[1G100.9 MiB [] 17% 2.3s\u001b[0K\u001b[1G100.9 MiB [] 18% 2.2s\u001b[0K\u001b[1G100.9 MiB [] 19% 2.2s\u001b[0K\u001b[1G100.9 MiB [] 20% 2.1s\u001b[0K\u001b[1G100.9 MiB [] 21% 2.1s\u001b[0K\u001b[1G100.9 MiB [] 22% 2.0s\u001b[0K\u001b[1G100.9 MiB [] 23% 2.1s\u001b[0K\u001b[1G100.9 MiB [] 24% 2.0s\u001b[0K\u001b[1G100.9 MiB [] 25% 2.0s\u001b[0K\u001b[1G100.9 MiB [] 26% 1.9s\u001b[0K\u001b[1G100.9 MiB [] 27% 1.9s\u001b[0K\u001b[1G100.9 MiB [] 28% 1.9s\u001b[0K\u001b[1G100.9 MiB [] 29% 1.9s\u001b[0K\u001b[1G100.9 MiB [] 30% 1.9s\u001b[0K\u001b[1G100.9 MiB [] 31% 1.9s\u001b[0K\u001b[1G100.9 MiB [] 32% 1.8s\u001b[0K\u001b[1G100.9 MiB [] 33% 1.7s\u001b[0K\u001b[1G100.9 MiB [] 34% 1.7s\u001b[0K\u001b[1G100.9 MiB [] 35% 1.7s\u001b[0K\u001b[1G100.9 MiB [] 36% 1.6s\u001b[0K\u001b[1G100.9 MiB [] 37% 1.6s\u001b[0K\u001b[1G100.9 MiB [] 39% 1.5s\u001b[0K\u001b[1G100.9 MiB [] 41% 1.4s\u001b[0K\u001b[1G100.9 MiB [] 42% 1.4s\u001b[0K\u001b[1G100.9 MiB [] 44% 1.3s\u001b[0K\u001b[1G100.9 MiB [] 46% 1.2s\u001b[0K\u001b[1G100.9 MiB [] 47% 1.2s\u001b[0K\u001b[1G100.9 MiB [] 48% 1.2s\u001b[0K\u001b[1G100.9 MiB [] 49% 1.2s\u001b[0K\u001b[1G100.9 MiB [] 50% 1.1s\u001b[0K\u001b[1G100.9 MiB [] 51% 1.1s\u001b[0K\u001b[1G100.9 MiB [] 52% 1.1s\u001b[0K\u001b[1G100.9 MiB [] 53% 1.1s\u001b[0K\u001b[1G100.9 MiB [] 54% 1.1s\u001b[0K\u001b[1G100.9 MiB [] 55% 1.0s\u001b[0K\u001b[1G100.9 MiB [] 56% 1.0s\u001b[0K\u001b[1G100.9 MiB [] 57% 1.0s\u001b[0K\u001b[1G100.9 MiB [] 58% 0.9s\u001b[0K\u001b[1G100.9 MiB [] 59% 0.9s\u001b[0K\u001b[1G100.9 MiB [] 61% 0.9s\u001b[0K\u001b[1G100.9 MiB [] 61% 0.8s\u001b[0K\u001b[1G100.9 MiB [] 63% 0.8s\u001b[0K\u001b[1G100.9 MiB [] 65% 0.8s\u001b[0K\u001b[1G100.9 MiB [] 66% 0.7s\u001b[0K\u001b[1G100.9 MiB [] 68% 0.7s\u001b[0K\u001b[1G100.9 MiB [] 69% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 71% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 72% 0.6s\u001b[0K\u001b[1G100.9 MiB [] 73% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 74% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 75% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 76% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 77% 0.5s\u001b[0K\u001b[1G100.9 MiB [] 79% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 80% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 81% 0.4s\u001b[0K\u001b[1G100.9 MiB [] 82% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 84% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 85% 0.3s\u001b[0K\u001b[1G100.9 MiB [] 87% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 89% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 90% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 91% 0.2s\u001b[0K\u001b[1G100.9 MiB [] 92% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 93% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 94% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 95% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 97% 0.1s\u001b[0K\u001b[1G100.9 MiB [] 97% 0.0s\u001b[0K\u001b[1G100.9 MiB [] 99% 0.0s\u001b[0K\u001b[1G100.9 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium Headless Shell 131.0.6778.33 (playwright build v1148) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1148\n",
            "Downloading Firefox 132.0 (playwright build v1466)\u001b[2m from https://playwright.azureedge.net/builds/firefox/1466/firefox-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G87.6 MiB [] 0% 0.0s\u001b[0K\u001b[1G87.6 MiB [] 0% 18.0s\u001b[0K\u001b[1G87.6 MiB [] 0% 13.8s\u001b[0K\u001b[1G87.6 MiB [] 0% 9.2s\u001b[0K\u001b[1G87.6 MiB [] 1% 4.0s\u001b[0K\u001b[1G87.6 MiB [] 2% 2.7s\u001b[0K\u001b[1G87.6 MiB [] 4% 2.1s\u001b[0K\u001b[1G87.6 MiB [] 5% 1.9s\u001b[0K\u001b[1G87.6 MiB [] 7% 1.6s\u001b[0K\u001b[1G87.6 MiB [] 9% 1.4s\u001b[0K\u001b[1G87.6 MiB [] 10% 1.3s\u001b[0K\u001b[1G87.6 MiB [] 11% 1.3s\u001b[0K\u001b[1G87.6 MiB [] 12% 1.4s\u001b[0K\u001b[1G87.6 MiB [] 13% 1.4s\u001b[0K\u001b[1G87.6 MiB [] 14% 1.4s\u001b[0K\u001b[1G87.6 MiB [] 16% 1.3s\u001b[0K\u001b[1G87.6 MiB [] 17% 1.3s\u001b[0K\u001b[1G87.6 MiB [] 18% 1.3s\u001b[0K\u001b[1G87.6 MiB [] 20% 1.2s\u001b[0K\u001b[1G87.6 MiB [] 21% 1.2s\u001b[0K\u001b[1G87.6 MiB [] 23% 1.1s\u001b[0K\u001b[1G87.6 MiB [] 26% 1.0s\u001b[0K\u001b[1G87.6 MiB [] 28% 0.9s\u001b[0K\u001b[1G87.6 MiB [] 30% 0.9s\u001b[0K\u001b[1G87.6 MiB [] 32% 0.9s\u001b[0K\u001b[1G87.6 MiB [] 34% 0.8s\u001b[0K\u001b[1G87.6 MiB [] 36% 0.8s\u001b[0K\u001b[1G87.6 MiB [] 39% 0.7s\u001b[0K\u001b[1G87.6 MiB [] 41% 0.7s\u001b[0K\u001b[1G87.6 MiB [] 42% 0.7s\u001b[0K\u001b[1G87.6 MiB [] 43% 0.7s\u001b[0K\u001b[1G87.6 MiB [] 44% 0.7s\u001b[0K\u001b[1G87.6 MiB [] 46% 0.6s\u001b[0K\u001b[1G87.6 MiB [] 48% 0.6s\u001b[0K\u001b[1G87.6 MiB [] 49% 0.6s\u001b[0K\u001b[1G87.6 MiB [] 51% 0.6s\u001b[0K\u001b[1G87.6 MiB [] 53% 0.5s\u001b[0K\u001b[1G87.6 MiB [] 53% 0.6s\u001b[0K\u001b[1G87.6 MiB [] 54% 0.6s\u001b[0K\u001b[1G87.6 MiB [] 55% 0.6s\u001b[0K\u001b[1G87.6 MiB [] 56% 0.6s\u001b[0K\u001b[1G87.6 MiB [] 57% 0.5s\u001b[0K\u001b[1G87.6 MiB [] 59% 0.5s\u001b[0K\u001b[1G87.6 MiB [] 61% 0.5s\u001b[0K\u001b[1G87.6 MiB [] 63% 0.5s\u001b[0K\u001b[1G87.6 MiB [] 64% 0.4s\u001b[0K\u001b[1G87.6 MiB [] 66% 0.4s\u001b[0K\u001b[1G87.6 MiB [] 67% 0.4s\u001b[0K\u001b[1G87.6 MiB [] 68% 0.4s\u001b[0K\u001b[1G87.6 MiB [] 70% 0.4s\u001b[0K\u001b[1G87.6 MiB [] 71% 0.4s\u001b[0K\u001b[1G87.6 MiB [] 73% 0.3s\u001b[0K\u001b[1G87.6 MiB [] 75% 0.3s\u001b[0K\u001b[1G87.6 MiB [] 76% 0.3s\u001b[0K\u001b[1G87.6 MiB [] 77% 0.3s\u001b[0K\u001b[1G87.6 MiB [] 79% 0.3s\u001b[0K\u001b[1G87.6 MiB [] 80% 0.2s\u001b[0K\u001b[1G87.6 MiB [] 82% 0.2s\u001b[0K\u001b[1G87.6 MiB [] 83% 0.2s\u001b[0K\u001b[1G87.6 MiB [] 85% 0.2s\u001b[0K\u001b[1G87.6 MiB [] 87% 0.1s\u001b[0K\u001b[1G87.6 MiB [] 89% 0.1s\u001b[0K\u001b[1G87.6 MiB [] 90% 0.1s\u001b[0K\u001b[1G87.6 MiB [] 92% 0.1s\u001b[0K\u001b[1G87.6 MiB [] 93% 0.1s\u001b[0K\u001b[1G87.6 MiB [] 94% 0.1s\u001b[0K\u001b[1G87.6 MiB [] 96% 0.0s\u001b[0K\u001b[1G87.6 MiB [] 97% 0.0s\u001b[0K\u001b[1G87.6 MiB [] 99% 0.0s\u001b[0K\u001b[1G87.6 MiB [] 100% 0.0s\u001b[0K\n",
            "Firefox 132.0 (playwright build v1466) downloaded to /root/.cache/ms-playwright/firefox-1466\n",
            "Downloading Webkit 18.2 (playwright build v2104)\u001b[2m from https://playwright.azureedge.net/builds/webkit/2104/webkit-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G95.5 MiB [] 0% 0.0s\u001b[0K\u001b[1G95.5 MiB [] 0% 16.6s\u001b[0K\u001b[1G95.5 MiB [] 0% 9.5s\u001b[0K\u001b[1G95.5 MiB [] 0% 5.9s\u001b[0K\u001b[1G95.5 MiB [] 1% 3.5s\u001b[0K\u001b[1G95.5 MiB [] 2% 2.8s\u001b[0K\u001b[1G95.5 MiB [] 3% 2.4s\u001b[0K\u001b[1G95.5 MiB [] 4% 2.3s\u001b[0K\u001b[1G95.5 MiB [] 5% 2.1s\u001b[0K\u001b[1G95.5 MiB [] 7% 2.0s\u001b[0K\u001b[1G95.5 MiB [] 8% 1.8s\u001b[0K\u001b[1G95.5 MiB [] 9% 1.7s\u001b[0K\u001b[1G95.5 MiB [] 10% 1.6s\u001b[0K\u001b[1G95.5 MiB [] 11% 1.7s\u001b[0K\u001b[1G95.5 MiB [] 12% 1.8s\u001b[0K\u001b[1G95.5 MiB [] 12% 1.9s\u001b[0K\u001b[1G95.5 MiB [] 13% 1.8s\u001b[0K\u001b[1G95.5 MiB [] 14% 1.7s\u001b[0K\u001b[1G95.5 MiB [] 16% 1.6s\u001b[0K\u001b[1G95.5 MiB [] 16% 1.7s\u001b[0K\u001b[1G95.5 MiB [] 17% 1.6s\u001b[0K\u001b[1G95.5 MiB [] 18% 1.7s\u001b[0K\u001b[1G95.5 MiB [] 19% 1.6s\u001b[0K\u001b[1G95.5 MiB [] 20% 1.5s\u001b[0K\u001b[1G95.5 MiB [] 22% 1.4s\u001b[0K\u001b[1G95.5 MiB [] 23% 1.4s\u001b[0K\u001b[1G95.5 MiB [] 24% 1.4s\u001b[0K\u001b[1G95.5 MiB [] 25% 1.4s\u001b[0K\u001b[1G95.5 MiB [] 26% 1.4s\u001b[0K\u001b[1G95.5 MiB [] 28% 1.3s\u001b[0K\u001b[1G95.5 MiB [] 29% 1.3s\u001b[0K\u001b[1G95.5 MiB [] 30% 1.2s\u001b[0K\u001b[1G95.5 MiB [] 31% 1.2s\u001b[0K\u001b[1G95.5 MiB [] 33% 1.2s\u001b[0K\u001b[1G95.5 MiB [] 34% 1.1s\u001b[0K\u001b[1G95.5 MiB [] 35% 1.1s\u001b[0K\u001b[1G95.5 MiB [] 36% 1.1s\u001b[0K\u001b[1G95.5 MiB [] 38% 1.0s\u001b[0K\u001b[1G95.5 MiB [] 39% 1.0s\u001b[0K\u001b[1G95.5 MiB [] 40% 1.0s\u001b[0K\u001b[1G95.5 MiB [] 42% 0.9s\u001b[0K\u001b[1G95.5 MiB [] 43% 0.9s\u001b[0K\u001b[1G95.5 MiB [] 45% 0.9s\u001b[0K\u001b[1G95.5 MiB [] 46% 0.8s\u001b[0K\u001b[1G95.5 MiB [] 48% 0.8s\u001b[0K\u001b[1G95.5 MiB [] 49% 0.8s\u001b[0K\u001b[1G95.5 MiB [] 50% 0.8s\u001b[0K\u001b[1G95.5 MiB [] 52% 0.7s\u001b[0K\u001b[1G95.5 MiB [] 54% 0.7s\u001b[0K\u001b[1G95.5 MiB [] 56% 0.7s\u001b[0K\u001b[1G95.5 MiB [] 57% 0.6s\u001b[0K\u001b[1G95.5 MiB [] 59% 0.6s\u001b[0K\u001b[1G95.5 MiB [] 60% 0.6s\u001b[0K\u001b[1G95.5 MiB [] 62% 0.6s\u001b[0K\u001b[1G95.5 MiB [] 63% 0.5s\u001b[0K\u001b[1G95.5 MiB [] 64% 0.5s\u001b[0K\u001b[1G95.5 MiB [] 65% 0.5s\u001b[0K\u001b[1G95.5 MiB [] 67% 0.5s\u001b[0K\u001b[1G95.5 MiB [] 68% 0.5s\u001b[0K\u001b[1G95.5 MiB [] 70% 0.4s\u001b[0K\u001b[1G95.5 MiB [] 72% 0.4s\u001b[0K\u001b[1G95.5 MiB [] 73% 0.4s\u001b[0K\u001b[1G95.5 MiB [] 75% 0.3s\u001b[0K\u001b[1G95.5 MiB [] 76% 0.3s\u001b[0K\u001b[1G95.5 MiB [] 78% 0.3s\u001b[0K\u001b[1G95.5 MiB [] 79% 0.3s\u001b[0K\u001b[1G95.5 MiB [] 81% 0.3s\u001b[0K\u001b[1G95.5 MiB [] 82% 0.2s\u001b[0K\u001b[1G95.5 MiB [] 84% 0.2s\u001b[0K\u001b[1G95.5 MiB [] 86% 0.2s\u001b[0K\u001b[1G95.5 MiB [] 87% 0.2s\u001b[0K\u001b[1G95.5 MiB [] 89% 0.1s\u001b[0K\u001b[1G95.5 MiB [] 90% 0.1s\u001b[0K\u001b[1G95.5 MiB [] 92% 0.1s\u001b[0K\u001b[1G95.5 MiB [] 93% 0.1s\u001b[0K\u001b[1G95.5 MiB [] 95% 0.1s\u001b[0K\u001b[1G95.5 MiB [] 97% 0.0s\u001b[0K\u001b[1G95.5 MiB [] 98% 0.0s\u001b[0K\u001b[1G95.5 MiB [] 99% 0.0s\u001b[0K\u001b[1G95.5 MiB [] 100% 0.0s\u001b[0K\n",
            "Webkit 18.2 (playwright build v2104) downloaded to /root/.cache/ms-playwright/webkit-2104\n",
            "Downloading FFMPEG playwright build v1010\u001b[2m from https://playwright.azureedge.net/builds/ffmpeg/1010/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 3% 0.5s\u001b[0K\u001b[1G2.3 MiB [] 12% 0.2s\u001b[0K\u001b[1G2.3 MiB [] 30% 0.1s\u001b[0K\u001b[1G2.3 MiB [] 60% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 99% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1010 downloaded to /root/.cache/ms-playwright/ffmpeg-1010\n",
            "Playwright Host validation warning: \n",
            "╔══════════════════════════════════════════════════════╗\n",
            "║ Host system is missing dependencies to run browsers. ║\n",
            "║ Missing libraries:                                   ║\n",
            "║     libwoff2dec.so.1.0.2                             ║\n",
            "║     libgstgl-1.0.so.0                                ║\n",
            "║     libgstcodecparsers-1.0.so.0                      ║\n",
            "║     libavif.so.13                                    ║\n",
            "║     libharfbuzz-icu.so.0                             ║\n",
            "║     libenchant-2.so.2                                ║\n",
            "║     libsecret-1.so.0                                 ║\n",
            "║     libhyphen.so.0                                   ║\n",
            "║     libmanette-0.2.so.0                              ║\n",
            "╚══════════════════════════════════════════════════════╝\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:216:9)\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\u001b[39m\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:753:43)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:851:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:840:43)\n",
            "    at async t.<anonymous> (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/cli/program.js:137:7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tournaments to pull data from\n",
        "tournaments_list = [\"https://gol.gg/tournament/tournament-matchlist/LCK%20Cup%202025/\"]\n",
        "\n",
        "# Stats to use\n",
        "stats_list = [\"Kills\", \"Deaths\", \"Assists\", \"CS\", \"Vision Score\", \"Total damage to Champion\", \"Time ccing others\"]\n",
        "\n",
        "# Set up the API scope\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
        "\n",
        "# Paths to stuff in the google drive\n",
        "path_to_creds = \"PATH_TO_GOOGLE_CREDENTIALS.json\"\n",
        "path_to_past_matches = \"PATH_TO_PAST_MATCHES_FILE.json\"\n",
        "sheet_name = \"MatchData\"\n",
        "spreadsheet_doc_name = \"Fantasy League of Legends - LCK Cup 2025\"\n",
        "\n",
        "# All stats so we can delete the ones we do not use later\n",
        "all_stats_list = ['Role', 'Level', 'Kills', 'Deaths', 'Assists', 'KDA', 'CS', \"CS in Team's Jungle\", 'CS in Enemy Jungle', 'CSM', 'Golds', 'GPM', 'GOLD%', 'Vision Score', 'Wards placed', 'Wards destroyed', 'Control Wards Purchased', 'Detector Wards Placed', 'VSPM', 'WPM', 'VWPM', 'WCPM', 'VS%', 'Total damage to Champion', 'Physical Damage', 'Magic Damage', 'True Damage', 'DPM', 'DMG%', 'K+A Per Minute', 'KP%', 'Solo kills', 'Double kills', 'Triple kills', 'Quadra kills', 'Penta kills', 'GD@15', 'CSD@15', 'XPD@15', 'LVLD@15', 'Objectives Stolen', 'Damage dealt to turrets', 'Damage dealt to buildings', 'Total heal', 'Total Heals On Teammates', 'Damage self mitigated', 'Total Damage Shielded On Teammates', 'Time ccing others', 'Total Time CC Dealt', 'Total damage taken', 'Total Time Spent Dead', 'Consumables purchased', 'Items Purchased', 'Shutdown bounty collected', 'Shutdown bounty lost']\n",
        "stats_to_delete = list(set(stats_list) ^ set(all_stats_list))\n",
        "print(stats_to_delete)\n",
        "\n",
        "# Count the number of matches each team has played in to set the week\n",
        "global_team_match_counter = {}\n",
        "\n",
        "# Check to ensure the match is actually over\n",
        "first_to = 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5I6q1FgD-gB",
        "outputId": "aeb0c77b-ed64-47e7-d535-9eee1abc6f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Items Purchased', 'Total Heals On Teammates', 'KP%', 'Golds', 'GPM', 'Detector Wards Placed', 'Physical Damage', 'GOLD%', 'WCPM', 'Objectives Stolen', 'Total heal', 'Solo kills', 'Shutdown bounty lost', 'CSM', 'Role', 'Quadra kills', 'Penta kills', 'GD@15', 'CSD@15', 'LVLD@15', 'KDA', 'Total damage taken', 'Damage dealt to buildings', 'WPM', 'Damage dealt to turrets', 'DPM', 'Magic Damage', 'DMG%', 'VWPM', 'VS%', 'Consumables purchased', 'Total Time Spent Dead', 'Total Damage Shielded On Teammates', 'Wards destroyed', 'XPD@15', 'Control Wards Purchased', 'VSPM', 'Total Time CC Dealt', 'CS in Enemy Jungle', 'Shutdown bounty collected', 'Level', \"CS in Team's Jungle\", 'True Damage', 'K+A Per Minute', 'Triple kills', 'Wards placed', 'Damage self mitigated', 'Double kills']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from playwright.async_api import async_playwright, Playwright\n",
        "import nest_asyncio\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Allow async functions to run inside of an async environment. This is required because jupyter notebooks are async\n",
        "# environments, and the playwright package forces us to use the async version because of this. However, to use the async\n",
        "# package, we must have it within an async function. So, we are using nest_asyncio.\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Parameters: playwright: the playwright object to use\n",
        "# tournaments: list of string urls to scrape for matches\n",
        "# get_matches reads all urls in the tournaments list and returns the ids of those matches,\n",
        "# along with the number of games in that match and both team names in a nested list\n",
        "async def get_matches(playwright: Playwright, tournaments):\n",
        "  # Set the playwright to firefow and open a new page\n",
        "  firefox = playwright.firefox\n",
        "  browser = await firefox.launch()\n",
        "  page = await browser.new_page()\n",
        "\n",
        "  # Initialize an empty list of game ids to return later\n",
        "  game_ids = []\n",
        "\n",
        "  # Loop through all tournament urls\n",
        "  for tournament in tournaments:\n",
        "    # Open the url for the tournament and wait for the page to load\n",
        "    await page.goto(tournament)\n",
        "    content = await page.content()\n",
        "    await page.wait_for_selector(\"tbody\")\n",
        "\n",
        "    # Get the table's HTML content\n",
        "    table_html = await page.inner_html(\"tbody\")  # Replace 'table' with specific selector if needed\n",
        "\n",
        "    # Use BeautifulSoup to parse the table\n",
        "    soup = BeautifulSoup(table_html, \"html.parser\")\n",
        "    rows = soup.find_all(\"tr\")\n",
        "\n",
        "    # Use regex to match the scores\n",
        "    score_pattern = re.compile(r'(\\d+) - (\\d+)')\n",
        "    link_pattern = re.compile(r'/(\\d+)/')\n",
        "\n",
        "    # Loop through all rows (matches) in the tournament page\n",
        "    for row in rows:\n",
        "      # Get the score, which looks like \"2 - 1\" or \"0 - 2\". Matches the regex pattern\n",
        "      score = row.find(name=\"td\", class_=[\"text-center\", \"footable-visible\"], string=score_pattern)\n",
        "      # If there's a score, the match has been played and we can get the data\n",
        "      # otherwise, do nothing\n",
        "      if score:\n",
        "        # Look for the game id in the row\n",
        "        link = row.find(\"a\").get(\"href\")\n",
        "        game_id = int(link_pattern.search(link).group(1))\n",
        "\n",
        "        # Get the outcome of the match (2 - 1) in numbers to get the number of games played\n",
        "        numbers = score_pattern.search(score.text)\n",
        "        num1, num2 = map(int, numbers.groups())\n",
        "\n",
        "        if not max(num1, num2) >= first_to:\n",
        "          continue\n",
        "\n",
        "        # Get the team names. It doesn't matter who won, but we need both team names\n",
        "        winning_team = row.find(name=\"td\", class_=[\"text_victory\"]).text\n",
        "        losing_team = row.find(name=\"td\", class_=[\"text_defeat\"]).text\n",
        "\n",
        "        # Add all this data to the game_ids to return\n",
        "        game_ids.append([game_id, num1 + num2, winning_team, losing_team])\n",
        "\n",
        "  # Reverse the list to make the oldest games go first\n",
        "  game_ids.reverse()\n",
        "  return game_ids\n",
        "\n"
      ],
      "metadata": {
        "id": "EBWnCNtCzkIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# playwright is a playwright object\n",
        "# match is a list of lists with this as the inner list pattern: [game_id, number_of_games, winning_team, losing_team]\n",
        "# get_match_data() gets these parameters and returns a pandas dataframe with the data of the players as the columns\n",
        "# and the stats defined in stats_list as the rows + the number of games played\n",
        "async def get_match_data(playwright: Playwright, match, stats_to_delete):\n",
        "  # Get firefix browser and open a new page\n",
        "  firefox = playwright.firefox\n",
        "  browser = await firefox.launch()\n",
        "  page = await browser.new_page()\n",
        "\n",
        "  # Create an empty dataframe to store the player data\n",
        "  total_player_data_df = pd.DataFrame()\n",
        "\n",
        "  # Loop through each game in the match. On the site, it's based on the first id, and adds one\n",
        "  # for each game in the match\n",
        "  for id in range(match[0], match[0] + match[1]):\n",
        "    # Create the url and open it\n",
        "    url = \"https://gol.gg/game/stats/\" + str(id) + \"/page-fullstats/\"\n",
        "    await page.goto(url)\n",
        "\n",
        "    # Wait for the table to load\n",
        "    await page.wait_for_selector(\"table\")\n",
        "\n",
        "    # Get the table's HTML content\n",
        "    table_html = await page.inner_html(\"table\")\n",
        "\n",
        "    # Use BeautifulSoup to parse the table\n",
        "    soup = BeautifulSoup(table_html, \"html.parser\")\n",
        "    rows = soup.find_all(\"tr\")\n",
        "    player_data_matrix = []\n",
        "\n",
        "    # Loop through all rows except the first one. The first row contains the champions, and we don't need that data\n",
        "    for i in range(1, len(rows)):\n",
        "      # Get the data within the rows\n",
        "      cols = rows[i].find_all([\"td\", \"th\"])\n",
        "      data = [col.text.strip() for col in cols]\n",
        "\n",
        "      # Add the data to the 2d list\n",
        "      player_data_matrix.append(data)\n",
        "\n",
        "    # Turn the list into a matrix\n",
        "    game_df = pd.DataFrame(player_data_matrix)\n",
        "\n",
        "    # Set the first row as column headers\n",
        "    game_df.columns = game_df.iloc[0]\n",
        "\n",
        "    # Drop the first row\n",
        "    game_df = game_df[1:]\n",
        "\n",
        "    # Make the indexes look nice\n",
        "    game_df.reset_index(drop=True, inplace=True)\n",
        "    game_df.set_index('Player', inplace=True)\n",
        "\n",
        "    # Remove all stats we don't want\n",
        "    game_df.drop(stats_to_delete, inplace=True)\n",
        "\n",
        "    # Make the data into all integers\n",
        "    game_df = game_df.astype(int)\n",
        "\n",
        "    # If the dataframe is empty, set the dataframe to the one we just made. Otherwise, add them together\n",
        "    if total_player_data_df.empty:\n",
        "      total_player_data_df = game_df\n",
        "    else:\n",
        "      column_labels_order = total_player_data_df.columns.tolist()\n",
        "      game_df = game_df[column_labels_order]\n",
        "      total_player_data_df += game_df\n",
        "  # Add a bottom row for the number of games\n",
        "  total_player_data_df.loc[\"Number of Games\"] = [match[1] for i in range(total_player_data_df.shape[1])]\n",
        "\n",
        "  # Make the data into all integers so it does not become a percentage on google sheets for some reason\n",
        "  total_player_data_df = total_player_data_df.astype(\"int32\")\n",
        "\n",
        "  # Add another row on the bottom to show which team each player is on\n",
        "  total_player_data_df.loc[\"Team\"] = [\"\" for i in range(total_player_data_df.shape[1])]\n",
        "\n",
        "  # Get the players on each team\n",
        "  # Wait for this page to load\n",
        "  url = \"https://gol.gg/game/stats/\" + str(match[0]) + \"/page-summary/\"\n",
        "  await page.goto(url)\n",
        "  await page.wait_for_selector(\"table\")\n",
        "\n",
        "  # Get the text of the headers and pick out the team names.\n",
        "  h1_texts = await page.locator('div.col-cadre h1').all_text_contents()\n",
        "  team1 = h1_texts[0]\n",
        "  team2 = h1_texts[2]\n",
        "  team_names = [team1, team2]\n",
        "\n",
        "  # Get the tables with the player names to match the teams to the players\n",
        "  tables = page.locator('table')\n",
        "\n",
        "  # Get the number of tables found\n",
        "  table_count = await tables.count()\n",
        "\n",
        "  # Loop through all tables and extract their text content or HTML\n",
        "  for i in range(table_count):\n",
        "    # Get the table html\n",
        "    table_html = await tables.nth(i).inner_html()\n",
        "    soup = BeautifulSoup(table_html, \"html.parser\")\n",
        "\n",
        "    # Get the names within the table\n",
        "    names = soup.find_all(\"a\")\n",
        "    for j in range(len(names)):\n",
        "      # Add the names to the players' column\n",
        "      print(names[j].text, team_names[i])\n",
        "      total_player_data_df.loc[\"Team\", names[j].text] = team_names[i]\n",
        "  return total_player_data_df\n"
      ],
      "metadata": {
        "id": "NzqyDv8XzKsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(global_team_match_counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBVl10hH11Ud",
        "outputId": "d0d2380b-098e-448a-854a-fba172bbf668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from gspread.exceptions import APIError\n",
        "from gspread.utils import rowcol_to_a1\n",
        "\n",
        "# parameter match_df is the dataframe of the match to upload to google sheets\n",
        "# update_sheet sends the data in the dataframe to google sheets\n",
        "def update_sheet(match_df, spreadsheet_doc_name):\n",
        "  # Path to the service account JSON file\n",
        "  credentials = ServiceAccountCredentials.from_json_keyfile_name(path_to_creds, scope)\n",
        "\n",
        "  # Authenticate and connect to Google Sheets\n",
        "  gc = gspread.authorize(credentials)\n",
        "\n",
        "  # Open the Google Sheet by name\n",
        "  spreadsheet = gc.open(spreadsheet_doc_name)\n",
        "\n",
        "  # Select a specific worksheet within the document\n",
        "  worksheet = spreadsheet.worksheet(sheet_name)\n",
        "\n",
        "  # Turn the top row of player names into a list\n",
        "  player_names_list = match_df.columns.tolist()\n",
        "\n",
        "  # Loop through the 10 players in the dataframe\n",
        "  for i in range(match_df.shape[1]):\n",
        "    # Turn the player's data into a vertical list\n",
        "    player_data = match_df[player_names_list[i]].values.reshape(-1, 1).tolist()\n",
        "\n",
        "    # Remove the last element (the team name)\n",
        "    team_name = player_data.pop()[0]\n",
        "    print(player_names_list[i])\n",
        "    print(player_data)\n",
        "\n",
        "    # Find the column of the player's name in the spreadsheet\n",
        "    player_cell_col = worksheet.find(player_names_list[i])\n",
        "\n",
        "    # If it does not exist already, add it to the list\n",
        "    if not player_cell_col:\n",
        "      print(\"Name does not exist in the sheet.\")\n",
        "      num_columns = len(worksheet.row_values(1))\n",
        "\n",
        "      # Add a column if we are running out. There's a weird quirk with insert_cols, where we can't insert at\n",
        "      # the end of the sheet, so we insert close to the end and do it before we reach the end, so we always have about a\n",
        "      # 2 column padding\n",
        "      if num_columns > 23:\n",
        "        worksheet.insert_cols([[]], col=num_columns - 1)\n",
        "        num_columns += 1\n",
        "      # Add the player's name to the sheet and get the column\n",
        "      worksheet.update_cell(1, num_columns + 1, player_names_list[i])\n",
        "      player_cell_col = worksheet.find(player_names_list[i])\n",
        "\n",
        "    # Get the column in terms of google sheets columns rather than a number\n",
        "    player_cell_col = rowcol_to_a1(1, player_cell_col.col).split('1')[0]\n",
        "\n",
        "    # Get the row of the match number\n",
        "    stat_cell_row = worksheet.find(\"Match \" + str(global_team_match_counter[team_name]) + \" \" + stats_list[0]).row\n",
        "\n",
        "    # Get the range to update and turn it into a google sheets range\n",
        "    cell_to_update_top = player_cell_col + str(stat_cell_row)\n",
        "    cell_to_update_bottom = player_cell_col + str(stat_cell_row + len(player_data))\n",
        "    update_range = cell_to_update_top + \":\" + cell_to_update_bottom\n",
        "\n",
        "    # Update the sheet\n",
        "    worksheet.update(player_data, update_range)"
      ],
      "metadata": {
        "id": "-sEsNShoUHG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# match is a parameter with the match id, number of games, winning team, and losing team in a list\n",
        "# update_num_matches adds the team name to the dictionary if it is not there already, and it increments\n",
        "# the number if it is there\n",
        "def update_num_matches(match):\n",
        "  if match[2] in global_team_match_counter:\n",
        "    global_team_match_counter[match[2]] += 1\n",
        "  else:\n",
        "    global_team_match_counter[match[2]] = 1\n",
        "\n",
        "  if match[3] in global_team_match_counter:\n",
        "    global_team_match_counter[match[3]] += 1\n",
        "  else:\n",
        "    global_team_match_counter[match[3]] = 1"
      ],
      "metadata": {
        "id": "zBvPti0yL9yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Gets all match ids of scraped matches\n",
        "def get_past_matches(path):\n",
        "  with open(path_to_past_matches, \"r\") as f:\n",
        "    past_matches = json.load(f)\n",
        "  return past_matches\n",
        "\n",
        "# Writes a list to the json file\n",
        "def write_past_matches(path, matches):\n",
        "  with open(path_to_past_matches, \"w\") as f:\n",
        "    json.dump(matches, f)"
      ],
      "metadata": {
        "id": "Z_salgENKdbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Runs the methods\n",
        "async def main():\n",
        "  # Reset the dictionary to make sure the match numbers are correct\n",
        "  global_team_match_counter.clear()\n",
        "\n",
        "  # Scrape the page for all matches\n",
        "  async with async_playwright() as playwright:\n",
        "    all_matches = await get_matches(playwright, tournaments_list)\n",
        "\n",
        "  # Loop through all matches\n",
        "  for league_match in all_matches:\n",
        "    # Increment the number of matches the team has played\n",
        "    update_num_matches(league_match)\n",
        "\n",
        "    # Get the past matches from the json file to see if this match has been scraped already\n",
        "    past_matches = get_past_matches(path_to_past_matches)\n",
        "\n",
        "    # If it has not been scraped already, scrape it. Otherwise, skip it\n",
        "    if not league_match[0] in past_matches:\n",
        "      # Scrape the webpage and get the data as a dataframe\n",
        "      async with async_playwright() as playwright:\n",
        "        match_df = await get_match_data(playwright, league_match, stats_to_delete)\n",
        "\n",
        "      # Use the data to update the sheet\n",
        "      update_sheet(match_df, spreadsheet_doc_name)\n",
        "\n",
        "      # Add the match we scraped to the json file for permanent storage\n",
        "      past_matches.append(league_match[0])\n",
        "      write_past_matches(path_to_past_matches, past_matches)\n",
        "\n",
        "      # Wait 1 minute so we don't make too many requests to the sheets api and get an error\n",
        "      time.sleep(60)\n",
        "    else:\n",
        "      print(\"Match Skipped: \" + str(league_match[0]))\n"
      ],
      "metadata": {
        "id": "5If6j3xfLlyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyxVOX7nNVRT",
        "outputId": "9d560847-2863-46b9-a936-d3965a676804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Match Skipped: 62967\n",
            "Match Skipped: 62970\n",
            "Match Skipped: 63017\n",
            "Match Skipped: 63020\n",
            "Match Skipped: 63023\n",
            "Match Skipped: 63026\n",
            "Match Skipped: 63029\n",
            "Match Skipped: 63032\n",
            "Match Skipped: 63035\n",
            "Match Skipped: 63038\n",
            "Match Skipped: 63158\n",
            "Match Skipped: 63161\n",
            "Match Skipped: 63164\n",
            "Match Skipped: 63167\n",
            "Match Skipped: 63170\n",
            "Match Skipped: 63173\n",
            "Match Skipped: 63176\n",
            "Match Skipped: 63179\n",
            "Match Skipped: 63182\n",
            "PerfecT KT Rolster\n",
            "Cuzz KT Rolster\n",
            "Bdd KT Rolster\n",
            "deokdam KT Rolster\n",
            "Way KT Rolster\n",
            "Morgan OK BRION\n",
            "HamBak OK BRION\n",
            "Clozer OK BRION\n",
            "Hype OK BRION\n",
            "Pollu OK BRION\n",
            "PerfecT\n",
            "[[8], [3], [18], [525], [87], [42028], [39], [2]]\n",
            "Cuzz\n",
            "[[5], [8], [18], [511], [149], [36289], [47], [2]]\n",
            "Bdd\n",
            "[[8], [2], [23], [696], [95], [54366], [43], [2]]\n",
            "deokdam\n",
            "[[13], [5], [13], [662], [84], [50665], [29], [2]]\n",
            "Way\n",
            "[[5], [11], [19], [75], [268], [20771], [57], [2]]\n",
            "Morgan\n",
            "[[9], [8], [6], [643], [108], [47100], [25], [2]]\n",
            "HamBak\n",
            "[[5], [11], [11], [439], [109], [22824], [31], [2]]\n",
            "Clozer\n",
            "[[7], [6], [11], [627], [89], [55269], [54], [2]]\n",
            "Hype\n",
            "[[7], [5], [12], [652], [99], [55877], [80], [2]]\n",
            "Pollu\n",
            "[[1], [9], [19], [55], [248], [12704], [82], [2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is for manually filling in the column in the data sheet. Just fills the leftmost column with the stats we want it to have\n",
        "def fill_data_column(num_matches):\n",
        "  # Path to the service account JSON file\n",
        "  credentials = ServiceAccountCredentials.from_json_keyfile_name(path_to_creds, scope)\n",
        "\n",
        "  # Authenticate and connect to Google Sheets\n",
        "  gc = gspread.authorize(credentials)\n",
        "\n",
        "  # Open the Google Sheet by name\n",
        "  spreadsheet = gc.open(\"Fantasy League of Legends - LCK Cup 2025\")\n",
        "\n",
        "  # Select a specific worksheet\n",
        "  worksheet = spreadsheet.worksheet(sheet_name)\n",
        "\n",
        "  column = []\n",
        "  for i in range(1, num_matches + 1):\n",
        "    for j in range(len(stats_list)):\n",
        "      column.append([\"Match \" + str(i) + \" \" + stats_list[j]])\n",
        "      if j == len(stats_list) - 1:\n",
        "        column.append([\"Match \" + str(i) + \" Number of Games\"])\n",
        "  print(column)\n",
        "  update_range = \"A2:A\"\n",
        "  worksheet.update(column, update_range)"
      ],
      "metadata": {
        "id": "bmZA6fXQHNuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lCzAvtKFyC_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}